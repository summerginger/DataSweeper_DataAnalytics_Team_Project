{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Ml_credit_application table from PostgreSQL database\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\r\n",
    "import pandas as pd\r\n",
    "import sqlalchemy\r\n",
    "from sqlalchemy.ext.automap import automap_base\r\n",
    "from sqlalchemy.orm import Session\r\n",
    "from sqlalchemy import create_engine, func\r\n",
    "import config as creds\r\n",
    "from collections import Counter\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "get_ipython().run_line_magic('load_ext', 'sql')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create connection with PostgreSQL databse\r\n",
    "get_ipython().run_line_magic('sql', 'postgresql://postgres:{creds.password}@{creds.path}:5432/postgres')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# reflect an existing database into a new model\r\n",
    "engine = create_engine(f\"postgresql://postgres:{creds.password}@{creds.path}:5432/postgres\")\r\n",
    "Base = automap_base()\r\n",
    "# reflect the tables\r\n",
    "Base.prepare(engine, reflect=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We can view all of the classes that automap found\r\n",
    "Base.classes.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['application_record', 'visual_creditapp']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "application = Base.classes.application_record\r\n",
    "session = Session(engine)\r\n",
    "results = []\r\n",
    "results = session.query(application)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Initial imports.\r\n",
    "from path import Path\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "credit_application_df = pd.read_csv(\"../resources/datasets/ML_credit_application.csv\")\r\n",
    "credit_application_df.drop(['ID'], axis=1, inplace=True)\r\n",
    "# Create our features\r\n",
    "X = credit_application_df.drop(columns=\"STATUS_y\")\r\n",
    "\r\n",
    "# Create our target\r\n",
    "y = pd.DataFrame(credit_application_df[\"STATUS_y\"])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the Data into Training and Testing\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\r\n",
    "\r\n",
    "Counter(y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Determine the shape of our training and testing sets.\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(27342, 13)\n",
      "(9115, 13)\n",
      "(27342, 1)\n",
      "(9115, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Creating a StandardScaler instance.\r\n",
    "scaler = StandardScaler()\r\n",
    "# Fitting the Standard Scaler with the training data.\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scaling the data.\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class Imbalance\r\n",
    "### The existing classes in the dataset is not equally represented. This is referred to as Class Imbalance and can cause the machine learning models to be biased toward the majority class. In this case, the machine learning models will be better at predicting not approved applicants. Hence, to counter this problem, we will be using Oversampling, Undersampling and Combination sampling techniques.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Oversampling technique: Random Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Resample the training data with the RandomOversampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "ros = RandomOverSampler()\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\r\n",
    "\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3533</td>\n",
       "      <td>3546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>977</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3533         3546\n",
       "Actual 1          977         1059"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5037849698299506\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.52      0.32      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.51      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.54      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5303</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>745</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5303         1776\n",
       "Actual 1          745         1291"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7234229292375206\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      7079\n",
      "           1       0.42      0.63      0.51      2036\n",
      "\n",
      "    accuracy                           0.72      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.77      0.72      0.74      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5390</td>\n",
       "      <td>1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>768</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5390         1689\n",
       "Actual 1          768         1268"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.730444322545255\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81      7079\n",
      "           1       0.43      0.62      0.51      2036\n",
      "\n",
      "    accuracy                           0.73      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.78      0.73      0.75      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2784539061841769, 'AGE'),\n",
       " (0.19195045754034373, 'EMPLOYMENT_PERIOD'),\n",
       " (0.1749618333203321, 'AMT_INCOME_TOTAL'),\n",
       " (0.0937260421740874, 'OCCUPATION_TYPE'),\n",
       " (0.04130590183355127, 'NAME_FAMILY_STATUS'),\n",
       " (0.03548501905223345, 'NAME_INCOME_TYPE'),\n",
       " (0.032966680947901936, 'CNT_FAM_MEMBERS'),\n",
       " (0.032425619251565445, 'NAME_EDUCATION_TYPE'),\n",
       " (0.026495885765129103, 'FLAG_OWN_REALTY'),\n",
       " (0.025344350648683775, 'CODE_GENDER'),\n",
       " (0.024757170591110225, 'CNT_CHILDREN'),\n",
       " (0.021430408121898753, 'NAME_HOUSING_TYPE'),\n",
       " (0.02069672456898586, 'FLAG_OWN_CAR')]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosted Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.518\n",
      "Accuracy score (validation): 0.502\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.535\n",
      "Accuracy score (validation): 0.516\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.574\n",
      "Accuracy score (validation): 0.545\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.566\n",
      "Accuracy score (validation): 0.544\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.592\n",
      "Accuracy score (validation): 0.566\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.585\n",
      "Accuracy score (validation): 0.563\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=1, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4067</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>970</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4067         3012\n",
       "Actual 1          970         1066"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5631376851343939\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67      7079\n",
      "           1       0.26      0.52      0.35      2036\n",
      "\n",
      "    accuracy                           0.56      9115\n",
      "   macro avg       0.53      0.55      0.51      9115\n",
      "weighted avg       0.69      0.56      0.60      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second Oversampling Technique: SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Resample the training data with SMOTE\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3570</td>\n",
       "      <td>3509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3570         3509\n",
       "Actual 1         1006         1030"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5046626439934174\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.51      0.31      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.50      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.55      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5944</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1004</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5944         1135\n",
       "Actual 1         1004         1032"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7653318705430608\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.48      0.51      0.49      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.67      0.67      0.67      9115\n",
      "weighted avg       0.77      0.77      0.77      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5938</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>968</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5938         1141\n",
       "Actual 1          968         1068"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7686231486560614\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.48      0.52      0.50      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.67      0.68      0.68      9115\n",
      "weighted avg       0.78      0.77      0.77      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.24973084078758476, 'AGE'),\n",
       " (0.1970309298165691, 'AMT_INCOME_TOTAL'),\n",
       " (0.1665797359783071, 'EMPLOYMENT_PERIOD'),\n",
       " (0.11439489148770804, 'OCCUPATION_TYPE'),\n",
       " (0.04794893935725789, 'NAME_FAMILY_STATUS'),\n",
       " (0.03736903461900153, 'NAME_INCOME_TYPE'),\n",
       " (0.03467286739080155, 'NAME_EDUCATION_TYPE'),\n",
       " (0.03392849712402746, 'CNT_FAM_MEMBERS'),\n",
       " (0.026249373517129287, 'FLAG_OWN_REALTY'),\n",
       " (0.024344276968012994, 'CNT_CHILDREN'),\n",
       " (0.023380428426889793, 'CODE_GENDER'),\n",
       " (0.022533284380848628, 'FLAG_OWN_CAR'),\n",
       " (0.02183690014586199, 'NAME_HOUSING_TYPE')]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# # Import pickle library\r\n",
    "import pickle\r\n",
    "\r\n",
    "dictionary = {\"model\": rf_model, \"scaler\": X_scaler}\r\n",
    "\r\n",
    "# # save the model to disk\r\n",
    "filename = 'randomForest_SMOTE_new.sav'\r\n",
    "pickle.dump(dictionary, open(filename, 'wb'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boost Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "## Gradient Boot Tree\r\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.557\n",
      "Accuracy score (validation): 0.533\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.559\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.600\n",
      "Accuracy score (validation): 0.573\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.613\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.639\n",
      "Accuracy score (validation): 0.618\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.651\n",
      "Accuracy score (validation): 0.628\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=0.75, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4871</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1278</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4871         2208\n",
       "Actual 1         1278          758"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6175534832693362\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      7079\n",
      "           1       0.26      0.37      0.30      2036\n",
      "\n",
      "    accuracy                           0.62      9115\n",
      "   macro avg       0.52      0.53      0.52      9115\n",
      "weighted avg       0.67      0.62      0.64      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Undersampling Technique: ClusterCentroids"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Resample the data using the ClusterCentroids resampler\r\n",
    "from imblearn.under_sampling import ClusterCentroids\r\n",
    "cc = ClusterCentroids(random_state=1)\r\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_under = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_under.fit(X_resampled, y_resampled) \r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "y_pred = model_under.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Undersampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "## Decision Tree\r\n",
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4866</td>\n",
       "      <td>2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>703</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4866         2213\n",
       "Actual 1          703         1333"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6800877674163467\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      7079\n",
      "           1       0.38      0.65      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4813</td>\n",
       "      <td>2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>689</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4813         2266\n",
       "Actual 1          689         1347"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.675809105869446\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.77      7079\n",
      "           1       0.37      0.66      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.25434520254723714, 'AGE'),\n",
       " (0.20316198111660222, 'EMPLOYMENT_PERIOD'),\n",
       " (0.18807378812315492, 'AMT_INCOME_TOTAL'),\n",
       " (0.09020690273157055, 'OCCUPATION_TYPE'),\n",
       " (0.043126401205716, 'NAME_FAMILY_STATUS'),\n",
       " (0.03543764033229364, 'NAME_EDUCATION_TYPE'),\n",
       " (0.03329217842199752, 'CNT_FAM_MEMBERS'),\n",
       " (0.030529455955449893, 'NAME_INCOME_TYPE'),\n",
       " (0.026130045742184724, 'FLAG_OWN_CAR'),\n",
       " (0.02557679979098576, 'NAME_HOUSING_TYPE'),\n",
       " (0.025036656559007803, 'CNT_CHILDREN'),\n",
       " (0.02289553700677564, 'FLAG_OWN_REALTY'),\n",
       " (0.022187410467024077, 'CODE_GENDER')]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Combination (Over and Under) Sampling Technique: SMOTEENN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resample the training data with SMOTEENN\r\n",
    "from imblearn.combine import SMOTEENN\r\n",
    "\r\n",
    "smote_enn = SMOTEENN(random_state=1)\r\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled,y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_comb = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_comb.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "y_pred = model_comb.predict(X_test_scaled)\r\n",
    "\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Print the imbalanced classification report\r\n",
    "print(\"Combination (Over and Under) Sampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combination (Over and Under) Sampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "d3d69a7e49531545e4a045ccba3269a9ab79e5c7d2e2c2f2e1b5eb667026ccb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}