{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Ml_credit_application table from PostgreSQL database\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\r\n",
    "import pandas as pd\r\n",
    "import sqlalchemy\r\n",
    "from sqlalchemy.ext.automap import automap_base\r\n",
    "from sqlalchemy.orm import Session\r\n",
    "from sqlalchemy import create_engine, func\r\n",
    "import config as creds\r\n",
    "from collections import Counter\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "get_ipython().run_line_magic('load_ext', 'sql')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create connection with PostgreSQL databse\r\n",
    "get_ipython().run_line_magic('sql', 'postgresql://postgres:{creds.password}@{creds.path}:5432/postgres')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# reflect an existing database into a new model\r\n",
    "engine = create_engine(f\"postgresql://postgres:{creds.password}@{creds.path}:5432/postgres\")\r\n",
    "Base = automap_base()\r\n",
    "# reflect the tables\r\n",
    "Base.prepare(engine, reflect=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We can view all of the classes that automap found\r\n",
    "Base.classes.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['application_record', 'visual_creditapp']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "application = Base.classes.application_record\r\n",
    "session = Session(engine)\r\n",
    "results = []\r\n",
    "results = session.query(application)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Initial imports.\r\n",
    "from path import Path\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "credit_application_df = pd.read_csv(\"../resources/ML_credit_application.csv\")\r\n",
    "credit_application_df.drop(['ID'], axis=1, inplace=True)\r\n",
    "# Create our features\r\n",
    "X = credit_application_df.drop(columns=\"STATUS_y\")\r\n",
    "\r\n",
    "# Create our target\r\n",
    "y = pd.DataFrame(credit_application_df[\"STATUS_y\"])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the Data into Training and Testing\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\r\n",
    "\r\n",
    "Counter(y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Determine the shape of our training and testing sets.\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(27342, 13)\n",
      "(9115, 13)\n",
      "(27342, 1)\n",
      "(9115, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Creating a StandardScaler instance.\r\n",
    "scaler = StandardScaler()\r\n",
    "# Fitting the Standard Scaler with the training data.\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scaling the data.\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class Imbalance\r\n",
    "### The existing classes in the dataset is not equally represented. This is referred to as Class Imbalance and can cause the machine learning models to be biased toward the majority class. In this case, the machine learning models will be better at predicting not approved applicants. Hence, to counter this problem, we will be using Oversampling, Undersampling and Combination sampling techniques.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Oversampling technique: Random Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Resample the training data with the RandomOversampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "ros = RandomOverSampler()\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\r\n",
    "\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3663</td>\n",
       "      <td>3416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1005</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3663         3416\n",
       "Actual 1         1005         1031"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5149753154141525\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.62      7079\n",
      "           1       0.23      0.51      0.32      2036\n",
      "\n",
      "    accuracy                           0.51      9115\n",
      "   macro avg       0.51      0.51      0.47      9115\n",
      "weighted avg       0.66      0.51      0.56      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5298</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>753</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5298         1781\n",
       "Actual 1          753         1283"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.721996708721887\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      7079\n",
      "           1       0.42      0.63      0.50      2036\n",
      "\n",
      "    accuracy                           0.72      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.77      0.72      0.74      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5410</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>792</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5410         1669\n",
       "Actual 1          792         1244"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7300054854635216\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81      7079\n",
      "           1       0.43      0.61      0.50      2036\n",
      "\n",
      "    accuracy                           0.73      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.77      0.73      0.75      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2760133395932255, 'AGE'),\n",
       " (0.1907250085025599, 'EMPLOYMENT_PERIOD'),\n",
       " (0.17474161870277877, 'AMT_INCOME_TOTAL'),\n",
       " (0.0946315454283008, 'OCCUPATION_TYPE'),\n",
       " (0.041023406612042776, 'NAME_FAMILY_STATUS'),\n",
       " (0.03532287029434483, 'NAME_INCOME_TYPE'),\n",
       " (0.03315812933749368, 'CNT_FAM_MEMBERS'),\n",
       " (0.03232044554659678, 'NAME_EDUCATION_TYPE'),\n",
       " (0.028077356100942846, 'FLAG_OWN_REALTY'),\n",
       " (0.02461151495649785, 'CNT_CHILDREN'),\n",
       " (0.024575967836564277, 'FLAG_OWN_CAR'),\n",
       " (0.024190397684946855, 'CODE_GENDER'),\n",
       " (0.02060839940370517, 'NAME_HOUSING_TYPE')]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosted Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.552\n",
      "Accuracy score (validation): 0.539\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.553\n",
      "Accuracy score (validation): 0.535\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.577\n",
      "Accuracy score (validation): 0.550\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.586\n",
      "Accuracy score (validation): 0.565\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.601\n",
      "Accuracy score (validation): 0.582\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.593\n",
      "Accuracy score (validation): 0.570\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=1, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4140</td>\n",
       "      <td>2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>979</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4140         2939\n",
       "Actual 1          979         1057"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5701590784421283\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.58      0.68      7079\n",
      "           1       0.26      0.52      0.35      2036\n",
      "\n",
      "    accuracy                           0.57      9115\n",
      "   macro avg       0.54      0.55      0.51      9115\n",
      "weighted avg       0.69      0.57      0.61      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second Oversampling Technique: SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Resample the training data with SMOTE\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3570</td>\n",
       "      <td>3509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3570         3509\n",
       "Actual 1         1006         1030"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5046626439934174\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.51      0.31      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.50      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.55      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5942</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5942         1137\n",
       "Actual 1         1000         1036"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7655512890839276\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.48      0.51      0.49      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.67      0.67      0.67      9115\n",
      "weighted avg       0.77      0.77      0.77      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5977</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>972</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5977         1102\n",
       "Actual 1          972         1064"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7724629731212287\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.49      0.52      0.51      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.68      0.68      0.68      9115\n",
      "weighted avg       0.78      0.77      0.77      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2481204484353481, 'AGE'),\n",
       " (0.19761818692765834, 'AMT_INCOME_TOTAL'),\n",
       " (0.16686284551771285, 'EMPLOYMENT_PERIOD'),\n",
       " (0.11467835074590879, 'OCCUPATION_TYPE'),\n",
       " (0.04847703002212588, 'NAME_FAMILY_STATUS'),\n",
       " (0.03726167135077544, 'NAME_INCOME_TYPE'),\n",
       " (0.034487754582167976, 'CNT_FAM_MEMBERS'),\n",
       " (0.03421320707232418, 'NAME_EDUCATION_TYPE'),\n",
       " (0.026328113632291514, 'FLAG_OWN_REALTY'),\n",
       " (0.024388108046662412, 'CNT_CHILDREN'),\n",
       " (0.023000962476327352, 'FLAG_OWN_CAR'),\n",
       " (0.02297841512119008, 'CODE_GENDER'),\n",
       " (0.021584906069507134, 'NAME_HOUSING_TYPE')]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# # Import pickle library\r\n",
    "import pickle\r\n",
    "\r\n",
    "# # save the model to disk\r\n",
    "filename = 'randomForest_SMOTE_new.sav'\r\n",
    "pickle.dump(rf_model, open(filename, 'wb'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boost Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "## Gradient Boot Tree\r\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.557\n",
      "Accuracy score (validation): 0.533\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.559\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.600\n",
      "Accuracy score (validation): 0.573\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.613\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.639\n",
      "Accuracy score (validation): 0.618\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.651\n",
      "Accuracy score (validation): 0.628\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=0.75, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4871</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1278</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4871         2208\n",
       "Actual 1         1278          758"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6175534832693362\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      7079\n",
      "           1       0.26      0.37      0.30      2036\n",
      "\n",
      "    accuracy                           0.62      9115\n",
      "   macro avg       0.52      0.53      0.52      9115\n",
      "weighted avg       0.67      0.62      0.64      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Undersampling Technique: ClusterCentroids"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Resample the data using the ClusterCentroids resampler\r\n",
    "from imblearn.under_sampling import ClusterCentroids\r\n",
    "cc = ClusterCentroids(random_state=1)\r\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'STATUS_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_under = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_under.fit(X_resampled, y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "y_pred = model_under.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Undersampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "## Decision Tree\r\n",
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4861</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>707</td>\n",
       "      <td>1329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4861         2218\n",
       "Actual 1          707         1329"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6791003839824465\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      7079\n",
      "           1       0.37      0.65      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4806</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>684</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4806         2273\n",
       "Actual 1          684         1352"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6755896873285793\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.76      7079\n",
      "           1       0.37      0.66      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2531039116399965, 'AGE'),\n",
       " (0.20144814995131766, 'EMPLOYMENT_PERIOD'),\n",
       " (0.18843828096402213, 'AMT_INCOME_TOTAL'),\n",
       " (0.09225785805687188, 'OCCUPATION_TYPE'),\n",
       " (0.04371638800659309, 'NAME_FAMILY_STATUS'),\n",
       " (0.03518962597648897, 'NAME_EDUCATION_TYPE'),\n",
       " (0.034329739783198, 'CNT_FAM_MEMBERS'),\n",
       " (0.03149167979008704, 'NAME_INCOME_TYPE'),\n",
       " (0.027737833001406174, 'FLAG_OWN_CAR'),\n",
       " (0.02554824726424193, 'CNT_CHILDREN'),\n",
       " (0.025216368080683456, 'NAME_HOUSING_TYPE'),\n",
       " (0.021007292085739725, 'FLAG_OWN_REALTY'),\n",
       " (0.02051462539935359, 'CODE_GENDER')]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Combination (Over and Under) Sampling Technique: SMOTEENN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resample the training data with SMOTEENN\r\n",
    "from imblearn.combine import SMOTEENN\r\n",
    "\r\n",
    "smote_enn = SMOTEENN(random_state=1)\r\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled,y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_comb = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_comb.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "y_pred = model_comb.predict(X_test_scaled)\r\n",
    "\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Print the imbalanced classification report\r\n",
    "print(\"Combination (Over and Under) Sampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combination (Over and Under) Sampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "d3d69a7e49531545e4a045ccba3269a9ab79e5c7d2e2c2f2e1b5eb667026ccb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}