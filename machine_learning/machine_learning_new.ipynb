{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Ml_credit_application table from PostgreSQL database\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\r\n",
    "import pandas as pd\r\n",
    "import sqlalchemy\r\n",
    "from sqlalchemy.ext.automap import automap_base\r\n",
    "from sqlalchemy.orm import Session\r\n",
    "from sqlalchemy import create_engine, func\r\n",
    "import config as creds\r\n",
    "from collections import Counter\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "get_ipython().run_line_magic('load_ext', 'sql')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create connection with PostgreSQL databse\r\n",
    "get_ipython().run_line_magic('sql', 'postgresql://postgres:{creds.password}@{creds.path}:5432/postgres')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# reflect an existing database into a new model\r\n",
    "engine = create_engine(f\"postgresql://postgres:{creds.password}@{creds.path}:5432/postgres\")\r\n",
    "Base = automap_base()\r\n",
    "# reflect the tables\r\n",
    "Base.prepare(engine, reflect=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We can view all of the classes that automap found\r\n",
    "Base.classes.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ml_application_record', 'application_record', 'visual_creditapp']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "credit_application_df = pd.read_sql('SELECT * FROM ml_application_record', engine)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "credit_application_df.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id                       int64\n",
       "code_gender              int64\n",
       "flag_own_car             int64\n",
       "flag_own_realty          int64\n",
       "cnt_children             int64\n",
       "amt_income_total       float64\n",
       "name_income_type         int64\n",
       "name_education_type      int64\n",
       "name_family_status       int64\n",
       "name_housing_type        int64\n",
       "occupation_type          int64\n",
       "cnt_fam_members        float64\n",
       "age                    float64\n",
       "employment_period      float64\n",
       "status_y                 int64\n",
       "code                     int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Initial imports.\r\n",
    "from path import Path\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "credit_application_df.drop(['id'], axis=1, inplace=True)\r\n",
    "credit_application_df.drop(['code'], axis=1, inplace=True)\r\n",
    "\r\n",
    "# Create our features\r\n",
    "X = credit_application_df.drop(columns=\"status_y\")\r\n",
    "\r\n",
    "# Create our target\r\n",
    "y = pd.DataFrame(credit_application_df[\"status_y\"])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the Data into Training and Testing\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\r\n",
    "\r\n",
    "Counter(y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Determine the shape of our training and testing sets.\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(27342, 13)\n",
      "(9115, 13)\n",
      "(27342, 1)\n",
      "(9115, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Creating a StandardScaler instance.\r\n",
    "scaler = StandardScaler()\r\n",
    "# Fitting the Standard Scaler with the training data.\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scaling the data.\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class Imbalance\r\n",
    "### The existing classes in the dataset is not equally represented. This is referred to as Class Imbalance and can cause the machine learning models to be biased toward the majority class. In this case, the machine learning models will be better at predicting not approved applicants. Hence, to counter this problem, we will be using Oversampling, Undersampling and Combination sampling techniques.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Oversampling technique: Random Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Resample the training data with the RandomOversampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "ros = RandomOverSampler()\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\r\n",
    "\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3539</td>\n",
       "      <td>3540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>986</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3539         3540\n",
       "Actual 1          986         1050"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5034558420186506\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.52      0.32      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.51      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.54      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5322</td>\n",
       "      <td>1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>740</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5322         1757\n",
       "Actual 1          740         1296"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.726055951727921\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      7079\n",
      "           1       0.42      0.64      0.51      2036\n",
      "\n",
      "    accuracy                           0.73      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.78      0.73      0.74      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5435</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>776</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5435         1644\n",
       "Actual 1          776         1260"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.734503565551289\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      7079\n",
      "           1       0.43      0.62      0.51      2036\n",
      "\n",
      "    accuracy                           0.73      9115\n",
      "   macro avg       0.65      0.69      0.66      9115\n",
      "weighted avg       0.78      0.73      0.75      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.27677096198765694, 'age'),\n",
       " (0.19195818771289055, 'employment_period'),\n",
       " (0.1740651816678719, 'amt_income_total'),\n",
       " (0.09328477681797231, 'occupation_type'),\n",
       " (0.03983330559178436, 'name_family_status'),\n",
       " (0.03536868453388802, 'name_income_type'),\n",
       " (0.03353757403712021, 'name_education_type'),\n",
       " (0.03260091704070759, 'cnt_fam_members'),\n",
       " (0.02699299670156437, 'flag_own_realty'),\n",
       " (0.025764170919673854, 'cnt_children'),\n",
       " (0.025089384859850968, 'code_gender'),\n",
       " (0.02241207968948978, 'flag_own_car'),\n",
       " (0.022321778439529198, 'name_housing_type')]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosted Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.540\n",
      "Accuracy score (validation): 0.522\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.542\n",
      "Accuracy score (validation): 0.517\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.566\n",
      "Accuracy score (validation): 0.541\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.569\n",
      "Accuracy score (validation): 0.546\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.594\n",
      "Accuracy score (validation): 0.573\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.574\n",
      "Accuracy score (validation): 0.547\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=1, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3871</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>920</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3871         3208\n",
       "Actual 1          920         1116"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5471201316511245\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.55      0.65      7079\n",
      "           1       0.26      0.55      0.35      2036\n",
      "\n",
      "    accuracy                           0.55      9115\n",
      "   macro avg       0.53      0.55      0.50      9115\n",
      "weighted avg       0.69      0.55      0.58      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second Oversampling Technique: SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Resample the training data with SMOTE\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "log_model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "predictions = log_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3570</td>\n",
       "      <td>3509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3570         3509\n",
       "Actual 1         1006         1030"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5046626439934174\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.51      0.31      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.50      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.55      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5931</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5931         1148\n",
       "Actual 1         1001         1035"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.7642347778387274\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.47      0.51      0.49      2036\n",
      "\n",
      "    accuracy                           0.76      9115\n",
      "   macro avg       0.66      0.67      0.67      9115\n",
      "weighted avg       0.77      0.76      0.77      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5978</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>978</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5978         1101\n",
       "Actual 1          978         1058"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.771914426769062\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.49      0.52      0.50      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.67      0.68      0.68      9115\n",
      "weighted avg       0.78      0.77      0.77      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2487366677990461, 'age'),\n",
       " (0.19699836083022954, 'amt_income_total'),\n",
       " (0.16750291288671937, 'employment_period'),\n",
       " (0.11391730489384921, 'occupation_type'),\n",
       " (0.047870084139161356, 'name_family_status'),\n",
       " (0.038016389182143395, 'name_income_type'),\n",
       " (0.03467169802828837, 'name_education_type'),\n",
       " (0.0340429085304141, 'cnt_fam_members'),\n",
       " (0.025576771208851965, 'flag_own_realty'),\n",
       " (0.024677012611349573, 'cnt_children'),\n",
       " (0.023625472758878396, 'code_gender'),\n",
       " (0.022503027748837952, 'flag_own_car'),\n",
       " (0.02186138938223044, 'name_housing_type')]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# # Import pickle library\r\n",
    "import pickle\r\n",
    "\r\n",
    "dictionary = {\"model\": rf_model, \"scaler\": X_scaler}\r\n",
    "\r\n",
    "# # save the model to disk\r\n",
    "filename = 'randomForest_SMOTE_new.sav'\r\n",
    "pickle.dump(dictionary, open(filename, 'wb'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boost Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "## Gradient Boot Tree\r\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "for learning_rate in learning_rates:\r\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=learning_rate,\r\n",
    "   max_features=5,\r\n",
    "   max_depth=3,\r\n",
    "   random_state=0)\r\n",
    "   classifier.fit(X_resampled, y_resampled)\r\n",
    "   print(\"Learning rate: \", learning_rate)\r\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_train_scaled,\r\n",
    "           y_train)))\r\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\r\n",
    "       classifier.score(\r\n",
    "           X_test_scaled,\r\n",
    "           y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.557\n",
      "Accuracy score (validation): 0.533\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.559\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.600\n",
      "Accuracy score (validation): 0.573\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.613\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.639\n",
      "Accuracy score (validation): 0.618\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.651\n",
      "Accuracy score (validation): 0.628\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\r\n",
    "   learning_rate=0.75, max_features=5, max_depth=3, random_state=0)\r\n",
    "\r\n",
    "GB_classifier.fit(X_resampled, y_resampled)\r\n",
    "predictions = GB_classifier.predict(X_test_scaled)\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\r\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\r\n",
    ")\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4871</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1278</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4871         2208\n",
       "Actual 1         1278          758"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6175534832693362\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      7079\n",
      "           1       0.26      0.37      0.30      2036\n",
      "\n",
      "    accuracy                           0.62      9115\n",
      "   macro avg       0.52      0.53      0.52      9115\n",
      "weighted avg       0.67      0.62      0.64      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Undersampling Technique: ClusterCentroids"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Resample the data using the ClusterCentroids resampler\r\n",
    "from imblearn.under_sampling import ClusterCentroids\r\n",
    "cc = ClusterCentroids(random_state=1)\r\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_under = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_under.fit(X_resampled, y_resampled) \r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Making predictions using the testing data.\r\n",
    "y_pred = model_under.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculated the accuracy score\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(\"Undersampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "## Decision Tree\r\n",
    "# Creating the decision tree classifier instance.\r\n",
    "tree_model = tree.DecisionTreeClassifier()\r\n",
    "# Fitting the model.\r\n",
    "tree_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "predictions = tree_model.predict(X_test_scaled)\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "# Calculating the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4864</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>708</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4864         2215\n",
       "Actual 1          708         1328"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6793198025233133\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      7079\n",
      "           1       0.37      0.65      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "## Random Forest\r\n",
    "# Create a random forest classifier.\r\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# Making predictions using the testing data.\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Calculating the confusion matrix.\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "# Calculating the accuracy score.\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "# Displaying results\r\n",
    "print(\"Confusion Matrix\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(\"Classification Report\")\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# We can sort the features by their importance.\r\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4817</td>\n",
       "      <td>2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>694</td>\n",
       "      <td>1342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4817         2262\n",
       "Actual 1          694         1342"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.6756993965990126\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.77      7079\n",
      "           1       0.37      0.66      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.2541399431441034, 'age'),\n",
       " (0.2005063691917014, 'employment_period'),\n",
       " (0.18756906878342727, 'amt_income_total'),\n",
       " (0.09208600339671669, 'occupation_type'),\n",
       " (0.043914556552202055, 'name_family_status'),\n",
       " (0.03501560531825361, 'cnt_fam_members'),\n",
       " (0.03472373143406642, 'name_education_type'),\n",
       " (0.03074141813172945, 'name_income_type'),\n",
       " (0.026626754792405075, 'cnt_children'),\n",
       " (0.025855210141755562, 'name_housing_type'),\n",
       " (0.02478419554301806, 'flag_own_car'),\n",
       " (0.022183146043609134, 'flag_own_realty'),\n",
       " (0.021853997527011983, 'code_gender')]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Combination (Over and Under) Sampling Technique: SMOTEENN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resample the training data with SMOTEENN\r\n",
    "from imblearn.combine import SMOTEENN\r\n",
    "\r\n",
    "smote_enn = SMOTEENN(random_state=1)\r\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled,y_train)\r\n",
    "Counter(y_resampled)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Train the Logistic Regression model using the resampled data\r\n",
    "model_comb = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model_comb.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "y_pred = model_comb.predict(X_test_scaled)\r\n",
    "\r\n",
    "acc_score = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create df for confusion matrix\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\r\n",
    "\r\n",
    "# Print the imbalanced classification report\r\n",
    "print(\"Combination (Over and Under) Sampling\")\r\n",
    "display(cm_df)\r\n",
    "print(f\"Accuracy Score : {acc_score}\")\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combination (Over and Under) Sampling\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>4019</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1161</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 4019                3060\n",
       "Actual Low Risk                  1161                 875"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.5369171695008228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.54      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.54      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "d3d69a7e49531545e4a045ccba3269a9ab79e5c7d2e2c2f2e1b5eb667026ccb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}