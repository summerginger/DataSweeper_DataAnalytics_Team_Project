{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Ml_credit_application table from PostgreSQL database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "import config as creds\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection with PostgreSQL databse\n",
    "get_ipython().run_line_magic('sql', 'postgresql://postgres:{creds.password}@{creds.path}:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "engine = create_engine(f\"postgresql://postgres:{creds.password}@{creds.path}:5432/postgres\")\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ml_application_record', 'application_record', 'visual_creditapp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_application_df = pd.read_sql('SELECT * FROM ml_application_record', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       int64\n",
       "code_gender              int64\n",
       "flag_own_car             int64\n",
       "flag_own_realty          int64\n",
       "cnt_children             int64\n",
       "amt_income_total       float64\n",
       "name_income_type         int64\n",
       "name_education_type      int64\n",
       "name_family_status       int64\n",
       "name_housing_type        int64\n",
       "occupation_type          int64\n",
       "cnt_fam_members        float64\n",
       "age                    float64\n",
       "employment_period      float64\n",
       "status_y                 int64\n",
       "code                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_application_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "from path import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_application_df.drop(['id'], axis=1, inplace=True)\n",
    "credit_application_df.drop(['code'], axis=1, inplace=True)\n",
    "\n",
    "# Create our features\n",
    "X = credit_application_df.drop(columns=\"status_y\")\n",
    "\n",
    "# Create our target\n",
    "y = pd.DataFrame(credit_application_df[\"status_y\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "Counter(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27342, 13)\n",
      "(9115, 13)\n",
      "(27342, 1)\n",
      "(9115, 1)\n"
     ]
    }
   ],
   "source": [
    "# Determine the shape of our training and testing sets.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance\n",
    "### The existing classes in the dataset is not equally represented. This is referred to as Class Imbalance and can cause the machine learning models to be biased toward the majority class. In this case, the machine learning models will be better at predicting not approved applicants. Hence, to counter this problem, we will be using Oversampling, Undersampling and Combination sampling techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Oversampling technique: Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "log_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3581</td>\n",
       "      <td>3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>998</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3581         3498\n",
       "Actual 1          998         1038"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5067471201316511\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.61      7079\n",
      "           1       0.23      0.51      0.32      2036\n",
      "\n",
      "    accuracy                           0.51      9115\n",
      "   macro avg       0.51      0.51      0.47      9115\n",
      "weighted avg       0.66      0.51      0.55      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5358</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>744</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5358         1721\n",
       "Actual 1          744         1292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7295666483817883\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81      7079\n",
      "           1       0.43      0.63      0.51      2036\n",
      "\n",
      "    accuracy                           0.73      9115\n",
      "   macro avg       0.65      0.70      0.66      9115\n",
      "weighted avg       0.78      0.73      0.75      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the decision tree classifier instance.\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "# Fitting the model.\n",
    "tree_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Making predictions using the testing data.\n",
    "predictions = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5453</td>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>778</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5453         1626\n",
       "Actual 1          778         1258"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7362589138782227\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      7079\n",
      "           1       0.44      0.62      0.51      2036\n",
      "\n",
      "    accuracy                           0.74      9115\n",
      "   macro avg       0.66      0.69      0.67      9115\n",
      "weighted avg       0.78      0.74      0.75      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.27962380456573216, 'age'),\n",
       " (0.1893929970490189, 'employment_period'),\n",
       " (0.17636899308299164, 'amt_income_total'),\n",
       " (0.09390600202173664, 'occupation_type'),\n",
       " (0.037965088921782165, 'name_family_status'),\n",
       " (0.03560385375260159, 'name_income_type'),\n",
       " (0.033910505839498506, 'name_education_type'),\n",
       " (0.03153913261538814, 'cnt_fam_members'),\n",
       " (0.025521511696113726, 'flag_own_realty'),\n",
       " (0.025333855521418976, 'code_gender'),\n",
       " (0.025040392686729016, 'cnt_children'),\n",
       " (0.024334399830820773, 'flag_own_car'),\n",
       " (0.021459462416167682, 'name_housing_type')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.569\n",
      "Accuracy score (validation): 0.559\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.555\n",
      "Accuracy score (validation): 0.537\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.587\n",
      "Accuracy score (validation): 0.564\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.587\n",
      "Accuracy score (validation): 0.564\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.593\n",
      "Accuracy score (validation): 0.566\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.592\n",
      "Accuracy score (validation): 0.565\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=learning_rate,\n",
    "   max_features=5,\n",
    "   max_depth=3,\n",
    "   random_state=0)\n",
    "   classifier.fit(X_resampled, y_resampled)\n",
    "   print(\"Learning rate: \", learning_rate)\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_train_scaled,\n",
    "           y_train)))\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_test_scaled,\n",
    "           y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4103</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>987</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4103         2976\n",
       "Actual 1          987         1049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5652221612726276\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.58      0.67      7079\n",
      "           1       0.26      0.52      0.35      2036\n",
      "\n",
      "    accuracy                           0.57      9115\n",
      "   macro avg       0.53      0.55      0.51      9115\n",
      "weighted avg       0.68      0.57      0.60      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=1, max_features=5, max_depth=3, random_state=0)\n",
    "\n",
    "GB_classifier.fit(X_resampled, y_resampled)\n",
    "predictions = GB_classifier.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Oversampling Technique: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "log_model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "log_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3570</td>\n",
       "      <td>3509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3570         3509\n",
       "Actual 1         1006         1030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5046626439934174\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.50      0.61      7079\n",
      "           1       0.23      0.51      0.31      2036\n",
      "\n",
      "    accuracy                           0.50      9115\n",
      "   macro avg       0.50      0.51      0.46      9115\n",
      "weighted avg       0.66      0.50      0.55      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5939</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5939         1140\n",
       "Actual 1         1006         1030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7645639056500274\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.47      0.51      0.49      2036\n",
      "\n",
      "    accuracy                           0.76      9115\n",
      "   macro avg       0.66      0.67      0.67      9115\n",
      "weighted avg       0.77      0.76      0.77      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the decision tree classifier instance.\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "# Fitting the model.\n",
    "tree_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "predictions = tree_model.predict(X_test_scaled)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5941</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>953</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5941         1138\n",
       "Actual 1          953         1083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7705979155238618\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      7079\n",
      "           1       0.49      0.53      0.51      2036\n",
      "\n",
      "    accuracy                           0.77      9115\n",
      "   macro avg       0.67      0.69      0.68      9115\n",
      "weighted avg       0.78      0.77      0.77      9115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.2477238536865936, 'age'),\n",
       " (0.1983105610004641, 'amt_income_total'),\n",
       " (0.16557038286916478, 'employment_period'),\n",
       " (0.11356949020017967, 'occupation_type'),\n",
       " (0.048186357602224915, 'name_family_status'),\n",
       " (0.03765446686237635, 'name_income_type'),\n",
       " (0.03464915022847497, 'cnt_fam_members'),\n",
       " (0.034301415308013, 'name_education_type'),\n",
       " (0.02568096328158778, 'flag_own_realty'),\n",
       " (0.02554388101941739, 'cnt_children'),\n",
       " (0.024028684809953647, 'flag_own_car'),\n",
       " (0.02379463300529934, 'code_gender'),\n",
       " (0.020986160126250576, 'name_housing_type')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pickle library\n",
    "import pickle\n",
    "\n",
    "dictionary = {\"model\": rf_model, \"scaler\": X_scaler}\n",
    "\n",
    "# # save the model to disk\n",
    "filename = 'randomForest_SMOTE_new.sav'\n",
    "pickle.dump(dictionary, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.557\n",
      "Accuracy score (validation): 0.533\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.559\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.600\n",
      "Accuracy score (validation): 0.573\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.613\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.639\n",
      "Accuracy score (validation): 0.618\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.651\n",
      "Accuracy score (validation): 0.628\n"
     ]
    }
   ],
   "source": [
    "## Gradient Boot Tree\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=learning_rate,\n",
    "   max_features=5,\n",
    "   max_depth=3,\n",
    "   random_state=0)\n",
    "   classifier.fit(X_resampled, y_resampled)\n",
    "   print(\"Learning rate: \", learning_rate)\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_train_scaled,\n",
    "           y_train)))\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_test_scaled,\n",
    "           y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4871</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1278</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4871         2208\n",
       "Actual 1         1278          758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6175534832693362\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      7079\n",
      "           1       0.26      0.37      0.30      2036\n",
      "\n",
      "    accuracy                           0.62      9115\n",
      "   macro avg       0.52      0.53      0.52      9115\n",
      "weighted avg       0.67      0.62      0.64      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GB_classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=0.75, max_features=5, max_depth=3, random_state=0)\n",
    "\n",
    "GB_classifier.fit(X_resampled, y_resampled)\n",
    "predictions = GB_classifier.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Undersampling Technique: ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'status_y': 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model_under = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model_under.fit(X_resampled, y_resampled) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>3978</td>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1153</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 3978                3101\n",
       "Actual Low Risk                  1153                 883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5332967635765222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.53      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.53      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using the testing data.\n",
    "y_pred = model_under.predict(X_test_scaled)\n",
    "\n",
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create df for confusion matrix\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\n",
    "\n",
    "# Displaying results\n",
    "print(\"Undersampling\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4846</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>712</td>\n",
       "      <td>1324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4846         2233\n",
       "Actual 1          712         1324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6769061985737795\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.77      7079\n",
      "           1       0.37      0.65      0.47      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "# Creating the decision tree classifier instance.\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "# Fitting the model.\n",
    "tree_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "predictions = tree_model.predict(X_test_scaled)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>4825</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>699</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         4825         2254\n",
       "Actual 1          699         1337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6760285244103127\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.77      7079\n",
      "           1       0.37      0.66      0.48      2036\n",
      "\n",
      "    accuracy                           0.68      9115\n",
      "   macro avg       0.62      0.67      0.62      9115\n",
      "weighted avg       0.76      0.68      0.70      9115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.25386679690437963, 'age'),\n",
       " (0.2006931046145296, 'employment_period'),\n",
       " (0.18858744378500858, 'amt_income_total'),\n",
       " (0.09140543048389282, 'occupation_type'),\n",
       " (0.044125070661008514, 'name_family_status'),\n",
       " (0.03598187240114381, 'name_education_type'),\n",
       " (0.03409067657305855, 'cnt_fam_members'),\n",
       " (0.03204490636583528, 'name_income_type'),\n",
       " (0.02594681582083996, 'name_housing_type'),\n",
       " (0.025612238309556536, 'flag_own_car'),\n",
       " (0.02538999645486738, 'cnt_children'),\n",
       " (0.0215936307521632, 'code_gender'),\n",
       " (0.020662016873716216, 'flag_own_realty')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128) \n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Combination (Over and Under) Sampling Technique: SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled,y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination (Over and Under) Sampling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted High Risk</th>\n",
       "      <th>Predicted Low Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual High Risk</th>\n",
       "      <td>3978</td>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Low Risk</th>\n",
       "      <td>1153</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted High Risk  Predicted Low Risk\n",
       "Actual High Risk                 3978                3101\n",
       "Actual Low Risk                  1153                 883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5332967635765222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65      7079\n",
      "           1       0.22      0.43      0.29      2036\n",
      "\n",
      "    accuracy                           0.53      9115\n",
      "   macro avg       0.50      0.50      0.47      9115\n",
      "weighted avg       0.65      0.53      0.57      9115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model_comb = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model_comb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model_comb.predict(X_test_scaled)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create df for confusion matrix\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "print(\"Combination (Over and Under) Sampling\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3d69a7e49531545e4a045ccba3269a9ab79e5c7d2e2c2f2e1b5eb667026ccb9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
